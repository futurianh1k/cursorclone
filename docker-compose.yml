services:
  # PostgreSQL Database
  postgres:
    image: postgres:15-alpine
    container_name: cursor-poc-postgres
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
      POSTGRES_DB: ${POSTGRES_DB:-cursor_poc}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "${POSTGRES_PORT:-5432}:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-postgres}"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - cursor-network

  # Redis Cache
  redis:
    image: redis:7-alpine
    container_name: cursor-poc-redis
    command: redis-server --appendonly yes
    volumes:
      - redis_data:/data
    ports:
      - "${REDIS_PORT:-6379}:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - cursor-network

  # API Server
  api:
    build:
      context: ./apps/api
      dockerfile: Dockerfile
    container_name: cursor-poc-api
    # Docker 소켓 접근을 위해 docker 그룹 추가
    group_add:
      - "983"  # docker 그룹 GID (호스트의 /var/run/docker.sock 그룹)
    environment:
      DATABASE_URL: postgresql+asyncpg://${POSTGRES_USER:-postgres}:${POSTGRES_PASSWORD:-postgres}@postgres:5432/${POSTGRES_DB:-cursor_poc}
      REDIS_URL: redis://redis:6379/0
      REDIS_POOL_SIZE: ${REDIS_POOL_SIZE:-10}
      JWT_SECRET_KEY: ${JWT_SECRET_KEY:-change-me-in-production}
      # Fernet 키 형식: 32 bytes URL-safe base64 encoded
      # 생성: python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"
      MASTER_ENCRYPTION_KEY: ${MASTER_ENCRYPTION_KEY:-jaBiuVcMi6kjiFSmvctoICAGe_iK_pJ8Swi0nljSFXw=}
      # ⚠️ 프로덕션에서는 명시적 도메인만 허용 (절대 * 사용 금지)
      CORS_ALLOWED_ORIGINS: ${CORS_ALLOWED_ORIGINS:-http://localhost:3000,http://127.0.0.1:3000,http://web:3000}
      # vLLM 서버 연동 (Docker 네트워크 내부)
      VLLM_BASE_URL: ${VLLM_BASE_URL:-http://cursor-poc-vllm:8000/v1}
      VLLM_MODEL: ${VLLM_MODEL:-Qwen/Qwen2.5-Coder-7B-Instruct}
      VLLM_API_KEY: ${VLLM_API_KEY:-}
      LOG_LEVEL: ${LOG_LEVEL:-INFO}
      # 프로덕션 모드 - 실제 vLLM 사용
      DEV_MODE: ${DEV_MODE:-false}
      # IDE 컨테이너 설정
      HOST_WORKSPACE_PATH: ${HOST_WORKSPACE_PATH:-/home/ubuntu/projects/cursor-onprem-poc/workspaces}
      IDE_CONTAINER_IMAGE: ${IDE_CONTAINER_IMAGE:-cursor-poc-code-server:latest}
      IDE_NETWORK: cursor-onprem-poc_cursor-network
      IDE_BASE_URL: ${IDE_BASE_URL:-http://10.10.10.151}
      # Optional: offline VSIX extensions directory on docker host (mounted into IDE container as /opt/extra-extensions)
      HOST_IDE_EXTENSIONS_PATH: ${HOST_IDE_EXTENSIONS_PATH:-/home/ubuntu/projects/cursor-onprem-poc/ide-extensions}
      # Optional: offline opencode.ai CLI directory on docker host (mounted into IDE container as /opt/opencode-cli)
      HOST_OPENCODE_CLI_PATH: ${HOST_OPENCODE_CLI_PATH:-/home/ubuntu/projects/cursor-onprem-poc/opencode-cli}
      # Optional: offline Android SDK directory on docker host (mounted into IDE container as /opt/android-sdk)
      HOST_ANDROID_SDK_PATH: ${HOST_ANDROID_SDK_PATH:-/home/ubuntu/projects/cursor-onprem-poc/android-sdk}
      # Tabby 자동완성 서버
      TABBY_ENDPOINT: ${TABBY_ENDPOINT:-http://cursor-poc-tabby:8080}
      VLLM_ENDPOINT: ${VLLM_ENDPOINT:-http://cursor-poc-vllm:8000/v1}
      # RAG / 벡터 DB 설정
      QDRANT_HOST: cursor-poc-qdrant
      QDRANT_PORT: 6333
      EMBEDDING_MODEL: ${EMBEDDING_MODEL:-BAAI/bge-base-en-v1.5}
      USE_LOCAL_EMBEDDING: ${USE_LOCAL_EMBEDDING:-true}
      # Gateway -> API 내부 인증 토큰
      GATEWAY_INTERNAL_TOKEN: ${GATEWAY_INTERNAL_TOKEN:-change-me-in-production}
      # (C) 임베딩 오프라인 모드 (금융권/VDE 권장)
      # - 모델을 사전 다운로드해 ./models 아래에 배치하고, API 컨테이너에 read-only로 마운트
      # - 캐시는 named volume(vllm_cache)로 공유하여 외부 다운로드 없이 재시작에도 유지
      EMBEDDING_MODEL_PATH: ${EMBEDDING_MODEL_PATH:-/models/embedding}
      EMBEDDING_CACHE_DIR: ${EMBEDDING_CACHE_DIR:-/root/.cache/huggingface}
      EMBEDDING_LOCAL_FILES_ONLY: ${EMBEDDING_LOCAL_FILES_ONLY:-false}
      EMBEDDING_STRICT: ${EMBEDDING_STRICT:-false}
    volumes:
      - ./workspaces:/workspaces
      - ./apps/api/.env:/app/.env:ro
      - ./packages:/packages:ro
      # 오프라인 임베딩 모델 디렉토리 (사용 시)
      - ./models:/models:ro
      # HuggingFace 캐시(임베딩/토크나이저 등) — vLLM 캐시와 공유
      - vllm_cache:/root/.cache/huggingface
      # Docker 소켓 마운트 (IDE 컨테이너 관리용)
      - /var/run/docker.sock:/var/run/docker.sock
    ports:
      - "${API_PORT:-8000}:8000"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8000/health')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - cursor-network
    restart: unless-stopped

  # ============================================================
  # AI Gateway (FastAPI) — v0.3
  # - 모든 AI 요청은 Gateway를 경유 (PRD DoD)
  # - Upstream auth 분리 (workspace 토큰 전달 금지)
  # ============================================================
  gateway:
    # 외부 인터넷 의존성 추가를 피하기 위해, 이미 빌드된 api 이미지(runtime deps 포함)를 재사용
    image: cursor-onprem-poc-api
    container_name: cursor-poc-gateway
    working_dir: /app/gateway
    command: ["python", "-m", "uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8081"]
    environment:
      # newarchitecture: 운영 형태(JWKS 기반). 개발에서 dev 토큰을 쓰려면 true로 설정.
      JWT_DEV_MODE: ${JWT_DEV_MODE:-false}
      JWT_JWKS_URL: ${JWT_JWKS_URL:-http://cursor-poc-api:8000/api/auth/jwks}
      JWT_JWKS_CACHE_TTL_SECONDS: ${JWT_JWKS_CACHE_TTL_SECONDS:-300}
      JWT_JWKS_REFRESH_SECONDS: ${JWT_JWKS_REFRESH_SECONDS:-60}
      JWT_JWKS_FAIL_OPEN: ${JWT_JWKS_FAIL_OPEN:-false}
      # Upstreams
      UPSTREAM_TABBY: ${UPSTREAM_TABBY:-http://cursor-poc-tabby:8080}
      UPSTREAM_CHAT: ${UPSTREAM_CHAT:-http://cursor-poc-vllm:8000}
      UPSTREAM_AGENT: ${UPSTREAM_AGENT:-http://cursor-poc-api:8000}
      UPSTREAM_RAG: ${UPSTREAM_RAG:-http://cursor-poc-api:8000}
      # Upstream auth separation
      UPSTREAM_AUTH_MODE: ${UPSTREAM_AUTH_MODE:-none}
      # Gateway -> API (rag/agent) 내부 토큰 헤더 (Authorization과 분리)
      UPSTREAM_INTERNAL_TOKEN: ${GATEWAY_INTERNAL_TOKEN:-change-me-in-production}
      UPSTREAM_INTERNAL_TOKEN_HEADER: ${UPSTREAM_INTERNAL_TOKEN_HEADER:-x-internal-token}
      # Audit DB (partitioned audit_events)
      AUDIT_DB_DSN: postgresql+asyncpg://${POSTGRES_USER:-postgres}:${POSTGRES_PASSWORD:-postgres}@postgres:5432/${POSTGRES_DB:-cursor_poc}
      AUDIT_RETENTION_DAYS: ${AUDIT_RETENTION_DAYS:-365}
      # DLP
      DLP_STREAM_MODE: ${DLP_STREAM_MODE:-pre_only}
    volumes:
      - ./apps/gateway:/app/gateway:ro
    ports:
      - "${GATEWAY_PORT:-8081}:8081"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8081/healthz')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s
    networks:
      - cursor-network
    restart: unless-stopped

  # Web Frontend
  web:
    build:
      context: .
      dockerfile: ./apps/web/Dockerfile
    container_name: cursor-poc-web
    environment:
      NEXT_PUBLIC_API_URL: ${NEXT_PUBLIC_API_URL:-http://localhost:8000}
      NEXT_PUBLIC_GATEWAY_URL: ${NEXT_PUBLIC_GATEWAY_URL:-http://localhost:8081}
      NODE_ENV: ${NODE_ENV:-production}
    ports:
      - "${WEB_PORT:-3000}:3000"
    depends_on:
      - api
    healthcheck:
      test: ["CMD", "node", "-e", "fetch('http://localhost:3000/api/health').then(r => r.ok ? process.exit(0) : process.exit(1)).catch(() => process.exit(1))"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - cursor-network
    restart: unless-stopped

  # vLLM (LLM Inference Server)
  # GPU 메모리에 따른 모델 선택 (환경변수로 설정):
  # - 8GB:       Qwen/Qwen2.5-Coder-7B-Instruct (기본값)
  # - 16GB:      Qwen/Qwen2.5-Coder-14B-Instruct
  # - 24GB 이상: Qwen/Qwen2.5-Coder-32B-Instruct
  # GPU가 없는 환경: DEV_MODE=true로 API 설정하여 mock 응답 사용
  vllm:
    image: vllm/vllm-openai:latest
    container_name: cursor-poc-vllm
    environment:
      HUGGING_FACE_HUB_TOKEN: ${HF_TOKEN:-}
      VLLM_API_KEY: ${VLLM_API_KEY:-}
    command: >
      --model ${VLLM_MODEL:-Qwen/Qwen2.5-Coder-7B-Instruct}
      --host 0.0.0.0
      --port 8000
      --trust-remote-code
      --max-model-len ${VLLM_MAX_MODEL_LEN:-4096}
      --gpu-memory-utilization ${VLLM_GPU_MEMORY:-0.85}
      --dtype auto
    ports:
      - "${VLLM_PORT:-8001}:8000"
    volumes:
      - vllm_cache:/root/.cache/huggingface
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    networks:
      - cursor-network
    restart: unless-stopped
    healthcheck:
      # NOTE: vllm 이미지에는 python이 없을 수 있어 curl로 health 확인
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 60s
      timeout: 30s
      retries: 5
      # 모델 초기 다운로드/로딩에 시간이 걸릴 수 있어 start_period를 길게 둔다
      start_period: 900s

  # ============================================================
  # 커스텀 code-server 이미지 빌더
  # Tabby + Continue 확장 사전 설치
  # ============================================================
  code-server-builder:
    build:
      context: ./docker/code-server
      dockerfile: Dockerfile
    image: cursor-poc-code-server:latest
    container_name: cursor-poc-code-server-builder
    command: ["echo", "Image built successfully"]
    restart: "no"

  # ============================================================
  # Tabby (AI 코드 자동완성 서버)
  # Copilot 스타일 인라인 코드 완성
  # ============================================================
  tabby:
    image: tabbyml/tabby:latest
    container_name: cursor-poc-tabby
    # NOTE:
    # - tabbyml/tabby 내부 llama-server(embedding)가 libcuda.so.1에 링크되어 있어,
    #   NVIDIA 드라이버 라이브러리가 컨테이너에 주입되지 않으면 시작이 실패(exit 127)한다.
    # - 따라서 기본 tabby는 GPU 런타임을 사용한다.
    entrypoint: ["/opt/tabby/bin/tabby"]
    command: ["serve", "--model", "${TABBY_MODEL:-StarCoder2-3B}", "--device", "cuda", "--no-webserver"]
    environment:
      TABBY_DISABLE_USAGE_COLLECTION: "1"
      TABBY_DISABLE_AUTH: "1"
    volumes:
      - tabby_data:/data
    ports:
      - "${TABBY_PORT:-8082}:8080"
    networks:
      - cursor-network
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/v1/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      # 캐시 초기화 후 모델 준비에 시간이 걸릴 수 있음
      start_period: 600s
    # GPU로 띄우려면 별도 서비스(tabby-gpu) 대신 이 서비스 기본 사용을 권장

  # GPU 버전(선택)
  tabby-gpu:
    image: tabbyml/tabby:latest
    container_name: cursor-poc-tabby-gpu
    entrypoint: ["/opt/tabby/bin/tabby"]
    command: ["serve", "--model", "${TABBY_MODEL:-StarCoder2-3B}", "--device", "cuda", "--no-webserver"]
    environment:
      TABBY_DISABLE_USAGE_COLLECTION: "1"
      TABBY_DISABLE_AUTH: "1"
    volumes:
      - tabby_data:/data
    ports:
      - "${TABBY_GPU_PORT:-8083}:8080"
    networks:
      - cursor-network
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/v1/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 120s
    profiles:
      - gpu

  # ============================================================
  # Qdrant (벡터 데이터베이스 - 코드 RAG용)
  # 코드 임베딩 저장 및 유사도 검색
  # ============================================================
  qdrant:
    image: qdrant/qdrant:latest
    container_name: cursor-poc-qdrant
    volumes:
      - qdrant_data:/qdrant/storage
    ports:
      - "${QDRANT_PORT:-6333}:6333"
      - "${QDRANT_GRPC_PORT:-6334}:6334"
    environment:
      QDRANT__SERVICE__GRPC_PORT: 6334
    networks:
      - cursor-network
    restart: unless-stopped
    # NOTE: qdrant 기본 이미지에는 curl/wget가 없어 healthcheck 오탐(unhealthy)이 발생할 수 있음
    healthcheck:
      disable: true

  # (기존 tabby-cpu 서비스는 tabby 기본 서비스로 통합)

  # Prometheus (Monitoring)
  prometheus:
    image: prom/prometheus:latest
    container_name: cursor-poc-prometheus
    volumes:
      - ./infra/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
    ports:
      - "${PROMETHEUS_PORT:-9090}:9090"
    networks:
      - cursor-network
    restart: unless-stopped
    profiles:
      - monitoring

  # Grafana (Visualization)
  grafana:
    image: grafana/grafana:latest
    container_name: cursor-poc-grafana
    environment:
      GF_SECURITY_ADMIN_USER: ${GRAFANA_ADMIN_USER:-admin}
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_ADMIN_PASSWORD:-admin}
      GF_INSTALL_PLUGINS: grafana-piechart-panel
      GF_SERVER_ROOT_URL: ${GRAFANA_ROOT_URL:-http://localhost:3001}
    volumes:
      - grafana_data:/var/lib/grafana
      - ./infra/grafana/provisioning:/etc/grafana/provisioning:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
    ports:
      - "${GRAFANA_PORT:-3001}:3000"
    networks:
      - cursor-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Portainer (Docker Management UI)
  portainer:
    image: portainer/portainer-ce:latest
    container_name: cursor-poc-portainer
    command: -H unix:///var/run/docker.sock
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - portainer_data:/data
    ports:
      - "${PORTAINER_PORT:-9000}:9000"
      - "${PORTAINER_AGENT_PORT:-9443}:9443"
    networks:
      - cursor-network
    restart: unless-stopped
    # NOTE: portainer 이미지에는 wget/curl/sh 등이 없어 healthcheck 오탐(unhealthy)이 발생할 수 있음
    healthcheck:
      disable: true

volumes:
  postgres_data:
  redis_data:
  prometheus_data:
  grafana_data:
  portainer_data:
  vllm_cache:
  tabby_data:
  qdrant_data:

networks:
  cursor-network:
    driver: bridge
